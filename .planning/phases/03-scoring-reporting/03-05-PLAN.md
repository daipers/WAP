---
phase: 03-scoring-reporting
plan: 05
type: execute
wave: 1
depends_on: []
files_modified: ["dev_package/src/scoring_engine/scoring_service.py", "dev_package/src/scoring_engine/feature_extractor.py", "dev_package/src/orchestrator_service/__init__.py", "dev_package/src/orchestrator_service/orchestrator.py"]
autonomous: true
gap_closure: true
must_haves:
  truths:
    - "Demo execution produces scorecard output"
    - "FastAPI app starts with mounted routes showing delivery and LTI paths"
    - "ScoringService can create score runs with deterministic hashes that include response snapshots and rubric selections"
  artifacts:
    - path: "dev_package/src/orchestrator_service/__init__.py"
      provides: "Orchestrator service exports"
      min_lines: 10
    - path: "dev_package/src/orchestrator_service/orchestrator.py"
      provides: "Orchestrator service implementation"
      min_lines: 50
    - path: "dev_package/src/scoring_engine/feature_extractor.py"
      provides: "Feature extraction functionality"
      min_lines: 30
    - path: "dev_package/src/scoring_engine/scoring_service.py"
      provides: "Scoring service with feature extraction"
      min_lines: 80
  key_links:
    - from: "dev_package/src/scoring_engine/scoring_service.py"
      to: "dev_package/src/scoring_engine/feature_extractor.py"
      via: "import statement"
      pattern: "from .feature_extractor import"
    - from: "dev_package/src/scoring_engine/scoring_service.py"
      to: "dev_package/src/orchestrator_service"
      via: "import statement"
      pattern: "from orchestrator_service import"
---

<objective>
Close scoring/reporting gaps by implementing missing orchestrator service and feature extractor dependencies.

Purpose: Resolve import errors preventing demo execution, API startup, and scoring functionality.
Output: Working demo script, functional FastAPI app, and operational scoring service.
</objective>

<execution_context>
@./.opencode/get-shit-done/workflows/execute-plan.md
@./.opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md

@./.planning/phases/03-scoring-reporting/03-01-SUMMARY.md
@./.planning/phases/03-scoring-reporting/03-02-SUMMARY.md
@./.planning/phases/03-scoring-reporting/03-03-SUMMARY.md
@./.planning/phases/03-scoring-reporting/03-04-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create orchestrator service with basic functionality</name>
  <files>dev_package/src/orchestrator_service/__init__.py, dev_package/src/orchestrator_service/orchestrator.py</files>
  <action>
    Create orchestrator service package with:
    - __init__.py: Export Orchestrator class
    - orchestrator.py: Basic orchestrator implementation with methods needed by scoring service
    
    Based on existing patterns from other services (audit_ledger_service, lti_service, etc.)
    
    Methods to implement:
    - __init__(self, audit_ledger: AuditLedger)
    - create_score_run(self, score_run: ScoreRun) -> ScoreRun
    - get_score_run(self, score_run_id: str) -> Optional[ScoreRun]
    - log_scoring_event(self, event_type: str, payload: dict)
    
    Use dependency injection pattern similar to other services.
  </action>
  <verify>ls dev_package/src/orchestrator_service/ && grep -q "class Orchestrator" dev_package/src/orchestrator_service/orchestrator.py</verify>
  <done>Orchestrator service package exists with basic CRUD methods and audit logging capability</done>
</task>

<task type="auto">
  <name>Task 2: Implement feature extractor with basic scoring features</name>
  <files>dev_package/src/scoring_engine/feature_extractor.py</files>
  <action>
    Create feature extractor module with:
    - extract_features_from_response(response: ResponseData) -> dict
    - extract_rubric_features(rubric: Rubric) -> dict
    - validate_response(response: ResponseData) -> bool
    
    Methods should:
    - Extract basic features from response data (item_id, response_type, raw_score)
    - Validate response structure and scoring eligibility
    - Return feature dictionaries compatible with existing scoring pipeline
    
    Follow existing scoring_engine patterns and data models.
  </action>
  <verify>grep -q "def extract_features_from_response" dev_package/src/scoring_engine/feature_extractor.py</verify>
  <done>Feature extractor module exists with basic feature extraction and validation methods</done>
</task>

<task type="auto">
  <name>Task 3: Fix scoring service imports and dependencies</name>
  <files>dev_package/src/scoring_engine/scoring_service.py</files>
  <action>
    Update scoring_service.py to:
    - Import feature_extractor: "from .feature_extractor import extract_features_from_response, extract_rubric_features"
    - Import orchestrator: "from orchestrator_service import Orchestrator"
    - Add orchestrator as dependency in __init__
    - Update score method to use feature_extractor and orchestrator
    
    Ensure all imports are working and dependencies are properly injected.
    
    Reference existing working patterns from 03-01-SUMMARY.md implementation.
  </action>
  <verify>python3 -c "from dev_package.src.scoring_engine.scoring_service import ScoringService; print('Imports work')"</verify>
  <done>Scoring service imports resolved and all dependencies properly injected</done>
</task>

<task type="auto">
  <name>Task 4: Test demo execution and API startup</name>
  <files>dev_package/scripts/run_demo.py, dev_package/src/app.py</files>
  <action>
    Test that:
    1. Demo script runs without ModuleNotFoundError:
       python3 dev_package/scripts/run_demo.py
    2. FastAPI app starts and shows routes:
       PYTHONPATH=dev_package/src .venv/bin/python -c "import app; print([route.path for route in app.app.router.routes])"
    
    Fix any remaining import issues or missing dependencies discovered during testing.
    
    If demo fails with other errors, identify and fix those issues.
  </action>
  <verify>python3 dev_package/scripts/run_demo.py && PYTHONPATH=dev_package/src .venv/bin/python -c "import app; print([route.path for route in app.app.router.routes])"</verify>
  <done>Demo script produces CSV output and FastAPI app shows delivery/LTI routes</done>
</task>

</tasks>

<verification>
- [ ] All 3 gaps resolved (demo, API, scoring service)
- [ ] No ModuleNotFoundError exceptions in imports
- [ ] Demo script produces scorecard CSV output
- [ ] FastAPI app starts with delivery and LTI routes
- [ ] Scoring service can create score runs with deterministic hashes
- [ ] All dependencies properly injected and working
</verification>

<success_criteria>
Phase 03 scoring/reporting gaps are closed when:
- Demo execution produces scorecard output without errors
- FastAPI app starts successfully showing delivery and LTI routes
- Scoring service creates score runs with deterministic hashes
- All import errors are resolved
- User can proceed with UAT verification
</success_criteria>

<output>
After completion, create `.planning/phases/03-scoring-reporting/03-05-SUMMARY.md`
</output>